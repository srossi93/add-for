{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-11T23:17:48.080546Z",
     "start_time": "2017-10-11T19:17:48.074561-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.contrib import layers\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers as layers_lib\n",
    "\n",
    "from keras.datasets import cifar10, mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Write TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:28:03.876350Z",
     "start_time": "2017-10-11T20:28:03.853913-04:00"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modified code from TensorFlow\n",
    "# Reference: tensorflow/examples/how_tos/reading_data/convert_to_records.py\n",
    "def _int64_feature(value):\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def convert_to(data_set, name):\n",
    "    \"\"\"Converts a dataset to tfrecords.\"\"\"\n",
    "    images = data_set[0]\n",
    "    labels = data_set[1]\n",
    "    num_examples = data_set[2]\n",
    "\n",
    "    if images.shape[0] != num_examples:\n",
    "        raise ValueError('Images size %d does not match label size %d.' %\n",
    "                     (images.shape[0], num_examples))\n",
    "    rows = images.shape[1]\n",
    "    cols = images.shape[2]\n",
    "    if len(images.shape == 4):\n",
    "        depth = images.shape[3]\n",
    "    else:\n",
    "        depth = 1\n",
    "\n",
    "    filename =  name + '.tfrecords'\n",
    "    print('Writing', filename, end=' ')\n",
    "    writer = tf.python_io.TFRecordWriter(filename)\n",
    "    for index in range(num_examples):\n",
    "        image_raw = images[index].tostring()\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'height': _int64_feature(rows),\n",
    "            'width': _int64_feature(cols),\n",
    "            'depth': _int64_feature(depth),\n",
    "            'label': _int64_feature(int(labels[index])),\n",
    "            'image_raw': _bytes_feature(image_raw)}))\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()\n",
    "    print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:28:04.882506Z",
     "start_time": "2017-10-11T20:28:04.642804-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:28:05.313835Z",
     "start_time": "2017-10-11T20:28:05.266183-04:00"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oneHotEncoding(labels):\n",
    "    numberOfClasses = len(list(set(labels)))\n",
    "    labelsOneHotEncodig = np.zeros([len(labels), numberOfClasses])\n",
    "    for i, label in enumerate(labels):\n",
    "        labelsOneHotEncodig[i][label] = 1\n",
    "    return labelsOneHotEncodig\n",
    "type(oneHotEncoding(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:29:35.910532Z",
     "start_time": "2017-10-11T20:28:40.991992-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.tfrecords done.\n"
     ]
    }
   ],
   "source": [
    "convert_to([x_train, y_train, len(x_train)], 'train')\n",
    "#convert_to([x_test, y_test, len(x_test)], 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Read TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:34:56.946726Z",
     "start_time": "2017-10-11T20:34:56.920014-04:00"
    },
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Modified code from TensorFlow\n",
    "# Reference: tensorflow/examples/how_tos/reading_data/fully_connected_reader.py\n",
    "\n",
    "def read_and_decode(filename_queue, shape):\n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    features = tf.parse_single_example(serialized_example,\n",
    "                                       features={'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                                                 'label': tf.FixedLenFeature([], tf.float32),})\n",
    "\n",
    "    # Convert from a scalar string tensor (whose single string has\n",
    "    # length mnist.IMAGE_PIXELS) to a uint8 tensor with shape\n",
    "    # [mnist.IMAGE_PIXELS].\n",
    "    image = tf.decode_raw(features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, shape)\n",
    "    #image.set_shape([image_pixels])\n",
    "\n",
    "    # Convert from [0, 255] -> [-0.5, 0.5] floats.\n",
    "    image = tf.cast(image, tf.float32)# * (1. / 255) - 0.5\n",
    "\n",
    "    # Convert label from a scalar uint8 tensor to an int32 scalar.\n",
    "    label = tf.cast(features['label'], tf.int32)\n",
    "    label = tf.one_hot(label, 10)\n",
    "    #label = tf.reshape(image, [1])\n",
    "    return image, label\n",
    "\n",
    "\n",
    "def inputs(train, batch_size, num_epochs, filename, shape):\n",
    "    if not num_epochs: num_epochs = None\n",
    "\n",
    "    with tf.name_scope('input'):\n",
    "        filename_queue = tf.train.string_input_producer(\n",
    "        [filename], num_epochs=num_epochs)\n",
    "\n",
    "    # Even when reading in multiple threads, share the filename\n",
    "    # queue.\n",
    "    image, label = read_and_decode(filename_queue, shape)\n",
    "\n",
    "    # Shuffle the examples and collect them into batch_size batches.\n",
    "    # (Internally uses a RandomShuffleQueue.)\n",
    "    # We run this in two threads to avoid being a bottleneck.\n",
    "    images, sparse_labels = tf.train.shuffle_batch(\n",
    "        [image, label], batch_size=batch_size, num_threads=2,\n",
    "        capacity=1000 + 3 * batch_size,\n",
    "        # Ensures a minimum amount of shuffling of examples.\n",
    "        min_after_dequeue=1000)\n",
    "    #sparse_labels = tf.reshape(sparse_labels, [-1, 10])\n",
    "    return images, sparse_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:34:57.400230Z",
     "start_time": "2017-10-11T20:34:57.314278-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "images, labels = inputs(train=True, batch_size=128,  num_epochs=5, \n",
    "                        filename='./train.tfrecords', shape=[32, 32, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:34:57.632558Z",
     "start_time": "2017-10-11T20:34:57.624159-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch_4:0' shape=(128, 32, 32, 3) dtype=float32>"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:34:58.158344Z",
     "start_time": "2017-10-11T20:34:58.152770-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'shuffle_batch_4:1' shape=(128, 10) dtype=float32>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "# Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:35:05.378236Z",
     "start_time": "2017-10-11T20:35:05.329116-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def alex_net(inputs, n_classes, prob=1., verbose=False):\n",
    "    input_layer = tf.reshape(inputs, [-1, 28, 28, 1])\n",
    "    print(input_layer) if verbose else 0\n",
    "    net = layers.conv2d(input_layer, 64, [3, 3], 2, padding='SAME', scope='conv1', activation_fn=tf.nn.relu, \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers_lib.max_pool2d(net, [3, 3], 2, scope='pool1')\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.conv2d(net, 192, [3, 3], scope='conv2', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers_lib.max_pool2d(net, [3, 3], 1, scope='pool2')\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.conv2d(net, 384, [3, 3], scope='conv3', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.conv2d(net, 384, [3, 3], scope='conv4', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.conv2d(net, 256, [3, 3], scope='conv5', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers_lib.max_pool2d(net, [3, 3], 2, scope='pool5')\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.fully_connected(net, num_outputs=4096, scope='fc1', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.dropout(net, prob)\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.fully_connected(net, num_outputs=4096, scope='fc2', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.dropout(net, prob)\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.fully_connected(net, num_outputs=n_classes, scope='fc3', activation_fn=tf.nn.relu,  \\\n",
    "                        weights_initializer=tf.truncated_normal_initializer(0, 0.1), \\\n",
    "                        biases_initializer=tf.truncated_normal_initializer(0.3, 0.1))\n",
    "    print(net) if verbose else 0\n",
    "    net = layers.softmax(net)\n",
    "    print(net) if verbose else 0\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:51:13.154068Z",
     "start_time": "2017-10-11T20:51:13.068124-04:00"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def LeNet5_Model(data, keep_prob=.5, activation='relu'):    \n",
    "    # --- level 1 --- #\n",
    "    #A 4-D tensor of shape [filter_height, filter_width, in_channels, out_channels]\n",
    "    # in_channels depens on the input img, out_channels is the number of desired filters\n",
    "    filters_conv_1 = weight_variable([5, 5, 1, 6])\n",
    "    window_pool_1 = [1, 2, 2, 1]\n",
    "    strides_conv_1 = [1, 1, 1, 1]\n",
    "    strides_pool_1 = [1, 2, 2, 1]\n",
    "    #the bias term is applied to each feature map\n",
    "    bias_layer_1 = bias_variable([6])\n",
    "    #we use SAME as padding because we want to keep the size of the original img 28x28,\n",
    "    #NOT 32x32 as expected\n",
    "    conv_layer_1 = tf.nn.conv2d(data, filters_conv_1, strides_conv_1, \"SAME\")\n",
    "    if activation=='relu':\n",
    "        hidden_layer_1 = tf.nn.relu(conv_layer_1 + bias_layer_1)\n",
    "    else:\n",
    "        hidden_layer_1 = tf.nn.sigmoid(conv_layer_1 + bias_layer_1)\n",
    "    pool_layer_1 = tf.nn.max_pool(hidden_layer_1, window_pool_1, strides_pool_1, \"VALID\")\n",
    "    \n",
    "    # --- end level 1 --- #\n",
    "    # --- level 2 --- #\n",
    "    filters_conv_2 = weight_variable([5, 5, 6, 16])\n",
    "    bias_layer_2 = bias_variable([16])\n",
    "    strides_conv_2 = [1, 1, 1, 1]\n",
    "    strides_pool_2 = [1, 2, 2, 1]\n",
    "    window_pool_2 = [1, 2, 2, 1]\n",
    "    strides_pool_2 = [1, 2, 2, 1]\n",
    "    \n",
    "    conv_layer_2 = tf.nn.conv2d(pool_layer_1, filters_conv_2, strides_conv_2, \"VALID\")\n",
    "    if activation=='relu':\n",
    "        hidden_layer_2 = tf.nn.relu(conv_layer_2 + bias_layer_2)\n",
    "    else:\n",
    "        hidden_layer_2 = tf.nn.sigmoid(conv_layer_2 + bias_layer_2)\n",
    "    pool_layer_2 = tf.nn.max_pool(hidden_layer_2, window_pool_2, strides_pool_2, \"VALID\")\n",
    "    flatten_l2 = tf.contrib.layers.flatten(pool_layer_2)\n",
    "    # --- end level 2 --- #\n",
    "\n",
    "    # --- level 3 --- #\n",
    "    l3_weights = weight_variable([16*5*5, 120])\n",
    "    l3_bias = bias_variable([120])\n",
    "    if activation=='relu':\n",
    "        hidden_layer_3 = tf.nn.relu(tf.matmul(flatten_l2, l3_weights) + l3_bias)\n",
    "    else:\n",
    "        hidden_layer_3 = tf.nn.sigmoid(tf.matmul(flatten_l2, l3_weights) + l3_bias)     \n",
    "    # --- end level 3 --- #\n",
    "    \n",
    "    # --- dropout layer --- #\n",
    "    drop_layer_1 = tf.nn.dropout(hidden_layer_3, keep_prob)\n",
    "    # --- end dropout layer --- #\n",
    "    \n",
    "    # --- level 4 --- #\n",
    "    l4_weights = weight_variable([120,84])\n",
    "    l4_bias = bias_variable([84])\n",
    "    if activation=='relu':\n",
    "        hidden_layer_4 = tf.nn.relu(tf.matmul(drop_layer_1, l4_weights) + l4_bias) \n",
    "    else:\n",
    "        hidden_layer_4 = tf.nn.sigmoid(tf.matmul(drop_layer_1, l4_weights) + l4_bias) \n",
    "    # --- end level 4 --- #\n",
    "    \n",
    "    # --- dropout layer --- #\n",
    "    drop_layer_2 = tf.nn.dropout(hidden_layer_4, keep_prob)\n",
    "    # --- end dropout layer --- #\n",
    "    \n",
    "    # --- level 5 --- #\n",
    "    l5_weights = weight_variable([84, 10])\n",
    "    l5_bias = bias_variable([10])\n",
    "    output = tf.nn.softmax(tf.matmul(drop_layer_2, l5_weights) + l5_bias)\n",
    "    # output = tf.matmul(hidden_layer_4, l5_weights) + l5_bias\n",
    "    # --- end level 5 --- #\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-12T00:51:15.591256Z",
     "start_time": "2017-10-11T20:51:15.551048-04:00"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def train(learning_rate=0.01, training_epochs=1, batch_size=128, \\\n",
    "          display_step=1, logs_path='./logs', keep_probability= 1.0):\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    x, y = inputs(train=True, batch_size=batch_size, num_epochs=training_epochs, \\\n",
    "                                filename='./train.tfrecords', shape=[28, 28, 1])\n",
    "    \n",
    "    #pred = alex_net(x, 10, keep_probability)\n",
    "    pred = LeNet5_Model(x)\n",
    "    \n",
    "    loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred+1e-9), reduction_indices=1))\n",
    "    #tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=tf.argmax(pred, axis=1), labels=(y)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1)), tf.float32))\n",
    "\n",
    "    init = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer())\n",
    "\n",
    "    tf.summary.scalar(\"Loss\", loss)\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)\n",
    "    merged_summary_op = tf.summary.merge_all()\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as session:\n",
    "        summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "        session.run(init)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=session, coord=coord)\n",
    "        \n",
    "        step = 0\n",
    "        try: \n",
    "            while not coord.should_stop():\n",
    "                start_time = time.time()\n",
    "                _, loss_value, summary = session.run([optimizer, loss, merged_summary_op])\n",
    "                duration = time.time() - start_time\n",
    "\n",
    "                # Print an overview fairly often.\n",
    "                if step % display_step == 0:\n",
    "                    start_time = time.time()\n",
    "                    print('Step %d: loss = %.2f - accuracy = %.2f (%.3f sec)' % (step, loss_value, accuracy.eval(), duration))\n",
    "                summary_writer.add_summary(summary, step)\n",
    "                step += 1  \n",
    "        except Exception:\n",
    "            print('Done training for %d epochs, %d steps.' % (num_epochs, step))\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-10-12T01:00:47.139Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0: loss = 16.55 - accuracy = 0.07 (0.219 sec)\n",
      "Step 100: loss = 0.89 - accuracy = 0.80 (0.052 sec)\n",
      "Step 200: loss = 0.40 - accuracy = 0.88 (0.053 sec)\n",
      "Step 300: loss = 0.45 - accuracy = 0.91 (0.055 sec)\n",
      "Step 400: loss = 0.15 - accuracy = 0.86 (0.055 sec)\n",
      "Step 500: loss = 0.22 - accuracy = 0.91 (0.054 sec)\n",
      "Step 600: loss = 0.48 - accuracy = 0.86 (0.057 sec)\n",
      "Step 700: loss = 0.25 - accuracy = 0.92 (0.053 sec)\n",
      "Step 800: loss = 0.26 - accuracy = 0.92 (0.051 sec)\n",
      "Step 900: loss = 0.08 - accuracy = 0.94 (0.056 sec)\n",
      "Step 1000: loss = 0.32 - accuracy = 0.93 (0.057 sec)\n"
     ]
    }
   ],
   "source": [
    "train(batch_size=100, display_step=100, training_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "4px",
    "width": "254px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
